@online {bib:data_storage_impact,
    author = "AJ Dellinger",
    title  = "The environmental impact of data storage is more than you think — and it’s only getting worse",
    month  = "jun",
    year   = "2019",
    note    = {\url{https://www.mic.com/impact/the-environmental-impact-of-data-storage-is-more-than-you-think-its-only-getting-worse-18017662}}

}

@online {bib:dna_data_storage,
    author = "John Bohannon",
    title  = "DNA: The Ultimate Hard Drive",
    month  = "aug",
    year   = "2012",
    note   = {\url{https://www.wired.com/2012/08/dna-data-storage}}

}

@inproceedings{bib:octree,
    author = {Kammerl, Julius and Blodow, Nico and Rusu, Radu and Gedikli, Suat and Beetz, Michael and Steinbach, Eckehard},
    year = {2012},
    month = {05},
    pages = {},
    title = {Real-time Compression of Point Cloud Streams},
    booktitle = {Proceedings - IEEE International Conference on Robotics and Automation},
    doi = {10.1109/ICRA.2012.6224647}
}

@inproceedings{bib:9102866,
    author={Wen, Xuanzheng and Wang, Xu and Hou, Junhui and Ma, Lin and Zhou, Yu and Jiang, Jianmin},  booktitle={2020 IEEE International Conference on Multimedia and Expo (ICME)},
    title={Lossy Geometry Compression Of 3d Point Cloud Data Via An Adaptive Octree-Guided Network},   year={2020},
    volume={},
    number={},
    pages={1-6},
    doi={10.1109/ICME46284.2020.9102866}
}

@inproceedings{bib:9287077,
    author={Quach, Maurice and Valenzise, Giuseppe and Dufaux, Frederic},
    booktitle={2020 IEEE 22nd International Workshop on Multimedia Signal Processing (MMSP)},
    title={Improved Deep Point Cloud Geometry Compression},
    year={2020},
    volume={},
    number={},
    pages={1-6},
    doi={10.1109/MMSP48831.2020.9287077}
}

@inproceedings{bib:8296925,
    author={Tian, Dong and Ochimizu, Hideaki and Feng, Chen and Cohen, Robert and Vetro, Anthony},
    booktitle={2017 IEEE International Conference on Image Processing (ICIP)},
    title={Geometric distortion metrics for point cloud compression},
    year={2017},
    volume={},
    number={},
    pages={3460-3464},
    doi={10.1109/ICIP.2017.8296925}
}

@article{bib:10.1093/bioinformatics/btaa140,
    author = {Schwarz, Michael and Welzel, Marius and Kabdullayeva, Tolganay and Becker, Anke and Freisleben, Bernd and Heider, Dominik},
    title = "{MESA: automated assessment of synthetic DNA fragments and simulation of DNA synthesis, storage, sequencing and PCR errors}",
    journal = {Bioinformatics},
    volume = {36},
    number = {11},
    pages = {3322-3326},
    year = {2020},
    month = {03},
    abstract = "{The development of de novo DNA synthesis, polymerase chain reaction (PCR), DNA sequencing and molecular cloning gave researchers unprecedented control over DNA and DNA-mediated processes. To reduce the error probabilities of these techniques, DNA composition has to adhere to method-dependent restrictions. To comply with such restrictions, a synthetic DNA fragment is often adjusted manually or by using custom-made scripts. In this article, we present MESA (Mosla Error Simulator), a web application for the assessment of DNA fragments based on limitations of DNA synthesis, amplification, cloning, sequencing methods and biological restrictions of host organisms. Furthermore, MESA can be used to simulate errors during synthesis, PCR, storage and sequencing processes.MESA is available at mesa.mosla.de, with the source code available at github.com/umr-ds/mesa\_dna\_sim.dominik.heider@uni-marburg.deSupplementary data are available at Bioinformatics online.}",
    issn = {1367-4803},
    doi = {10.1093/bioinformatics/btaa140},
    url = {https://doi.org/10.1093/bioinformatics/btaa140},
    eprint = {https://academic.oup.com/bioinformatics/article-pdf/36/11/3322/33329372/btaa140.pdf},
}

@article{bib:101038,
    author = {Kosuri, Sriram and Church, George},
    year = {2014},
    month = {04},
    pages = {499-507},
    title = {Large-scale de novo DNA synthesis: Technologies and applications},
    volume = {11},
    journal = {Nature methods},
    doi = {10.1038/nmeth.2918}
}

@article{bib:101371,
    author = {Jensen, Michael and Fukushima, Marilyn and Davis, Ronald},
    year = {2010},
    month = {06},
    pages = {e11024},
    title = {DMSO and Betaine Greatly Improve Amplification of GC-Rich Constructs in De Novo Synthesis},
    volume = {5},
    journal = {PloS one},
    doi = {10.1371/journal.pone.0011024}
}

@article{bib:102144,
    author = {Fazekas, Aron and Steeves, Royce and Newmaster, Steven},
    year = {2010},
    month = {04},
    pages = {277-85},
    title = {Improving sequencing quality from PCR products containing long mononucleotide repeats},
    volume = {48},
    journal = {BioTechniques},
    doi = {10.2144/000113369}
}

@article{bib:101093,
    author = {Laehnemann, David and Borkhardt, Arndt and McHardy, Alice},
    year = {2015},
    month = {05},
    pages = {},
    title = {Denoising DNA deep sequencing data--high-throughput sequencing errors and their correction},
    volume = {17},
    journal = {Briefings in bioinformatics},
    doi = {10.1093/bib/bbv029}
}

@article{bib:1012688,
    author = {Weirather, Jason and Cesare, Mariateresa de and Wang, Yunhao and Piazza, Paolo and Sebastiano, Vittorio and Wang, Xiu-Jie and Buck, David and Au, Kin},
    year = {2017},
    month = {06},
    pages = {100},
    title = {Comprehensive comparison of Pacific Biosciences and Oxford Nanopore Technologies and their applications to transcriptome analysis},
    volume = {6},
    journal = {F1000Research},
    doi = {10.12688/f1000research.10571.2}
}

@article{bib:101186,
    author = {Schirmer, Melanie and D'Amore, Rosalinda and Ijaz, Umer and Hall, Neil and Quince, Christopher},
    year = {2016},
    month = {03},
    pages = {},
    title = {Illumina error profiles: Resolving fine-scale variation in metagenomic sequencing data},
    volume = {17},
    journal = {BMC Bioinformatics},
    doi = {10.1186/s12859-016-0976-y}
}

@misc{bib:erlich_yaniv_2017_889697,
    author       = {Erlich, Yaniv and
                    Zielinski, Dina},
    title        = {{DNA Fountain enables a robust and efficient
                    storage architecture}},
    month        = mar,
    year         = 2017,
    publisher    = {Zenodo},
    doi          = {10.1126/science.aaj2038},
    url          = {https://doi.org/10.1126/science.aaj2038}
}

@article{bib:33649304,
    Title = {DNA stability: a central design consideration for DNA data storage systems},
    Author = {Matange, Karishma and Tuck, James M and Keung, Albert J},
    DOI = {10.1038/s41467-021-21587-5},
    Number = {1},
    Volume = {12},
    Month = {March},
    Year = {2021},
    Journal = {Nature communications},
    ISSN = {2041-1723},
    Pages = {1358},
    Abstract = {Data storage in DNA is a rapidly evolving technology that could be a transformative solution for the rising energy, materials, and space needs of modern information storage. Given that the information medium is DNA itself, its stability under different storage and processing conditions will fundamentally impact and constrain design considerations and data system capabilities. Here we analyze the storage conditions, molecular mechanisms, and stabilization strategies influencing DNA stability and pose specific design configurations and scenarios for future systems that best leverage the considerable advantages of DNA storage.},
    URL = {https://europepmc.org/articles/PMC7921107},
}

@article{bib:Mullis_1990,
    title={The Unusual Origin of the Polymerase Chain Reaction},
    volume={262},
    DOI={10.1038/scientificamerican0490-56},
    number={4},
    journal={Scientific American},
    author={Mullis, Kary B.},
    year={1990},
    month={Apr},
    pages={56–65},
}

@article{bib:goldman,
    author={Goldman, Nick
    and Bertone, Paul
    and Chen, Siyuan
    and Dessimoz, Christophe
    and LeProust, Emily M.
    and Sipos, Botond
    and Birney, Ewan},
    title={Towards practical, high-capacity, low-maintenance information storage in synthesized DNA},
    journal={Nature},
    year={2013},
    month={Feb},
    day={07},
    edition={2013/01/23},
    volume={494},
    number={7435},
    pages={77-80},
    keywords={*Archives; Base Sequence; Computers; DNA/*chemical synthesis/*chemistry/economics; Information Management/economics/*methods; Molecular Sequence Data; Sequence Analysis, DNA/economics; Synthetic Biology/economics/methods},
    abstract={Digital production, transmission and storage have revolutionized how we access and use information but have also made archiving an increasingly complex task that requires active, continuing maintenance of digital media. This challenge has focused some interest on DNA as an attractive target for information storage because of its capacity for high-density information encoding, longevity under easily achieved conditions and proven track record as an information bearer. Previous DNA-based information storage approaches have encoded only trivial amounts of information or were not amenable to scaling-up, and used no robust error-correction and lacked examination of their cost-efficiency for large-scale information archival. Here we describe a scalable method that can reliably store more information than has been handled before. We encoded computer files totalling 739 kilobytes of hard-disk storage and with an estimated Shannon information of 5.2{\thinspace}{\texttimes}{\thinspace}10(6) bits into a DNA code, synthesized this DNA, sequenced it and reconstructed the original files with 100{\%} accuracy. Theoretical analysis indicates that our DNA-based storage scheme could be scaled far beyond current global information volumes and offers a realistic technology for large-scale, long-term and infrequently accessed digital archiving. In fact, current trends in technological advances are reducing DNA synthesis costs at a pace that should make our scheme cost-effective for sub-50-year archiving within a decade.},
    note={23354052[pmid]},
    note={PMC3672958[pmcid]},
    note={nature11875[PII]},
    issn={1476-4687},
    doi={10.1038/nature11875},
    url={https://pubmed.ncbi.nlm.nih.gov/23354052},
    url={https://doi.org/10.1038/nature11875},
    language={eng}
}

@inproceedings{bib:paircode,
  author={Dimopoulou, Melpomeni and Antonini, Marc and Barbry, Pascal and Appuswamy, Raja},
  booktitle={2019 27th European Signal Processing Conference (EUSIPCO)}, 
  title={A biologically constrained encoding solution for long-term storage of images onto synthetic DNA}, 
  year={2019},
  volume={},
  number={},
  pages={1-5},
  abstract={Living in the age of the digital media explosion, the amount of data that is being stored increases dramatically. However, even if existing storage systems suggest efficiency in capacity, they are lacking in durability. Hard disks, flash, tape or even optical storage have limited lifespan in the range of 5 to 20 years. Interestingly, recent studies have proven that it was possible to use synthetic DNA for the storage of digital data, introducing a strong candidate to achieve data longevity. The DNA’s biological properties allows the storage of a great amount of information into an extraordinary small volume while also promising efficient storage for centuries or even longer with no loss of information. However, encoding digital data onto DNA is not obvious, because when decoding, we have to face the problem of sequencing noise robustness. Furthermore, synthesizing DNA is an expensive process and thus, controlling the compression ratio by optimizing the rate-distortion trade-off is an important challenge we have to deal with. This work proposes a coding solution for the storage of digital images onto synthetic DNA. We developed a new encoding algorithm which generates a DNA code robust to biological errors coming from the synthesis and the sequencing processes. Furthermore, thanks to an optimized allocation process the solution is able to control the compression ratio and thus the length of the synthesized DNA strand. Results show an improvement in terms of coding potential compared to previous state-of-the-art works.},
  keywords={},
  doi={10.23919/EUSIPCO.2019.8902583},
  ISSN={2076-1465},
  month={Sep.},
}

